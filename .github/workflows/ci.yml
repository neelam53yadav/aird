name: CI Pipeline

on:
  pull_request:
    branches:
      - main
      - db-fixes
  push:
    branches:
      - main
      - db-fixes

jobs:
  lint-backend:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          pip install flake8 black isort mypy
          # Use lightweight CI requirements to avoid disk space issues
          pip install -r requirements-ci.txt

      - name: Lint with flake8
        working-directory: backend
        run: |
          flake8 src/ --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 src/ --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Check formatting with black
        working-directory: backend
        run: black --check src/ --line-length 127

      - name: Check import sorting with isort
        working-directory: backend
        run: isort --check-only src/ --profile black --line-length 127

  test-backend:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_USER: primedata
          POSTGRES_PASSWORD: primedata123
          POSTGRES_DB: primedata_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # Note: MinIO is used in CI tests even though production uses GCS (Google Cloud Storage)
      # Reason: MinIO is S3-compatible and provides a lightweight, fast alternative for testing
      # The application code uses the same MinIO client interface for both MinIO and GCS
      # In production, GCS is accessed via S3-compatible API, so tests with MinIO validate the same code path
      - name: Start MinIO
        run: |
          docker run -d \
            --name minio \
            --network host \
            -e MINIO_ROOT_USER=minioadmin \
            -e MINIO_ROOT_PASSWORD=minioadmin \
            minio/minio:latest server /tmp/minio-data --console-address ":9001" &
          echo "Waiting for MinIO to start..."
          sleep 10
          for i in {1..30}; do
            if curl -f http://localhost:9000/minio/health/live 2>/dev/null; then
              echo "âœ… MinIO is ready!"
              break
            fi
            echo "Waiting for MinIO... (attempt $i/30)"
            sleep 2
          done

      - name: Install dependencies
        working-directory: backend
        run: |
          python -m pip install --upgrade pip
          # Use lightweight CI requirements (includes pytest)
          pip install -r requirements-ci.txt

      - name: Initialize MinIO buckets
        run: |
          pip install minio
          python -c "
          from minio import Minio
          client = Minio('localhost:9000', access_key='minioadmin', secret_key='minioadmin', secure=False)
          for bucket in ['primedata-raw', 'primedata-clean', 'primedata-exports', 'primedata-aird-artifacts']:
              try:
                  client.make_bucket(bucket)
                  print(f'Created bucket: {bucket}')
              except Exception as e:
                  print(f'Bucket {bucket} already exists or error: {e}')
          "

      - name: Run tests
        working-directory: backend
        env:
          DATABASE_URL: postgresql://primedata:primedata123@localhost:5432/primedata_test
          TEST_DATABASE_URL: postgresql://primedata:primedata123@localhost:5432/primedata_test
          MINIO_ENDPOINT: localhost:9000
          MINIO_ACCESS_KEY: minioadmin
          MINIO_SECRET_KEY: minioadmin
          MINIO_SECURE: 'false'
          DISABLE_AUTH: 'true'
        run: |
          pytest tests/ -v --cov=src --cov-report=xml

      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./backend/coverage.xml
          flags: backend

  lint-frontend:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '18'

      - name: Install dependencies
        working-directory: ui
        run: npm ci

      - name: Lint
        working-directory: ui
        run: npm run lint || echo "Lint check skipped"

      - name: Type check
        working-directory: ui
        run: npm run type-check || echo "Type check skipped"

  build-images:
    runs-on: ubuntu-latest
    needs: [lint-backend, lint-frontend]  # Only build if linting passes
    if: always() && (needs.lint-backend.result == 'success' && needs.lint-frontend.result == 'success')
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build backend image
        uses: docker/build-push-action@v5
        with:
          context: ./backend
          push: false
          tags: primedata-backend:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build frontend image
        uses: docker/build-push-action@v5
        with:
          context: ./ui
          push: false
          tags: primedata-frontend:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build Airflow image
        uses: docker/build-push-action@v5
        with:
          context: ./infra/airflow
          push: false
          tags: primedata-airflow:test
          cache-from: type=gha
          cache-to: type=gha,mode=max

