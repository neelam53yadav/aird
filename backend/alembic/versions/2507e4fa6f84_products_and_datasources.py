"""products_and_datasources

Revision ID: 2507e4fa6f84
Revises: ab76775a482b
Create Date: 2025-09-19 13:18:53.166593

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy import inspect, text
from sqlalchemy.dialects import postgresql


# revision identifiers, used by Alembic.
revision = '2507e4fa6f84'
down_revision = 'ab76775a482b'
branch_labels = None
depends_on = None


def table_exists(table_name):
    """Check if a table exists in the database."""
    bind = op.get_bind()
    inspector = inspect(bind)
    return table_name in inspector.get_table_names()


def enum_exists(enum_name):
    """Check if a PostgreSQL ENUM type exists."""
    bind = op.get_bind()
    result = bind.execute(
        text("""
            SELECT EXISTS (
                SELECT 1 FROM pg_type WHERE typname = :enum_name
            )
        """),
        {"enum_name": enum_name}
    )
    return result.scalar()


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Create productstatus enum if it doesn't exist using postgresql.ENUM
    if not enum_exists('productstatus'):
        productstatus_enum = postgresql.ENUM('DRAFT', 'RUNNING', 'READY', 'FAILED', name='productstatus', create_type=True)
        productstatus_enum.create(op.get_bind())
    else:
        # ENUM already exists, create a reference without creating the type
        productstatus_enum = postgresql.ENUM('DRAFT', 'RUNNING', 'READY', 'FAILED', name='productstatus', create_type=False)
    
    # Create datasourcetype enum if it doesn't exist using postgresql.ENUM
    if not enum_exists('datasourcetype'):
        datasourcetype_enum = postgresql.ENUM('WEB', 'DB', 'CONFLUENCE', 'SHAREPOINT', 'FOLDER', name='datasourcetype', create_type=True)
        datasourcetype_enum.create(op.get_bind())
    else:
        # ENUM already exists, create a reference without creating the type
        datasourcetype_enum = postgresql.ENUM('WEB', 'DB', 'CONFLUENCE', 'SHAREPOINT', 'FOLDER', name='datasourcetype', create_type=False)
    
    # Create products table
    if not table_exists('products'):
        op.create_table('products',
            sa.Column('id', sa.UUID(), nullable=False),
            sa.Column('workspace_id', sa.UUID(), nullable=False),
            sa.Column('owner_user_id', sa.UUID(), nullable=False),
            sa.Column('name', sa.String(length=255), nullable=False),
            sa.Column('status', productstatus_enum, nullable=False),
            sa.Column('current_version', sa.Integer(), nullable=False),
            sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
            sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
            sa.ForeignKeyConstraint(['owner_user_id'], ['users.id'], ),
            sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ),
            sa.PrimaryKeyConstraint('id'),
            sa.UniqueConstraint('workspace_id', 'name', name='unique_workspace_product_name')
        )
        op.create_index('idx_products_owner_user_id', 'products', ['owner_user_id'], unique=False)
        op.create_index('idx_products_workspace_id', 'products', ['workspace_id'], unique=False)
        op.create_index(op.f('ix_products_id'), 'products', ['id'], unique=False)
        op.create_index(op.f('ix_products_workspace_id'), 'products', ['workspace_id'], unique=False)
    
    # Check if data_sources table needs to be recreated (has old schema vs new schema)
    # Check if table has 'name' column (old schema) or 'product_id' column (new schema)
    bind = op.get_bind()
    needs_recreate = False
    if table_exists('data_sources'):
        inspector = inspect(bind)
        columns = [col['name'] for col in inspector.get_columns('data_sources')]
        # If it has 'name' column, it's the old schema, needs to be recreated
        if 'name' in columns:
            needs_recreate = True
        # If it doesn't have 'product_id', it needs to be recreated
        elif 'product_id' not in columns:
            needs_recreate = True
    
    if needs_recreate:
        op.drop_table('data_sources')
    
    # Create data_sources table with new schema if it doesn't exist
    if not table_exists('data_sources'):
        op.create_table('data_sources',
            sa.Column('id', sa.UUID(), nullable=False),
            sa.Column('workspace_id', sa.UUID(), nullable=False),
            sa.Column('product_id', sa.UUID(), nullable=False),
            sa.Column('type', datasourcetype_enum, nullable=False),
            sa.Column('config', sa.JSON(), nullable=False),
            sa.Column('last_cursor', sa.JSON(), nullable=True),
            sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
            sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
            sa.ForeignKeyConstraint(['product_id'], ['products.id'], ),
            sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ),
            sa.PrimaryKeyConstraint('id')
        )
        op.create_index('idx_data_sources_product_id', 'data_sources', ['product_id'], unique=False)
        op.create_index('idx_data_sources_workspace_id', 'data_sources', ['workspace_id'], unique=False)
        op.create_index(op.f('ix_data_sources_id'), 'data_sources', ['id'], unique=False)
        op.create_index(op.f('ix_data_sources_product_id'), 'data_sources', ['product_id'], unique=False)
        op.create_index(op.f('ix_data_sources_workspace_id'), 'data_sources', ['workspace_id'], unique=False)
    else:
        # Table exists with new schema, ensure indices exist (skip if they already do)
        inspector = inspect(bind)
        try:
            existing_indices = [idx['name'] for idx in inspector.get_indexes('data_sources')]
            if 'idx_data_sources_product_id' not in existing_indices:
                op.create_index('idx_data_sources_product_id', 'data_sources', ['product_id'], unique=False)
            if 'idx_data_sources_workspace_id' not in existing_indices:
                op.create_index('idx_data_sources_workspace_id', 'data_sources', ['workspace_id'], unique=False)
            if 'ix_data_sources_id' not in existing_indices:
                op.create_index(op.f('ix_data_sources_id'), 'data_sources', ['id'], unique=False)
            if 'ix_data_sources_product_id' not in existing_indices:
                op.create_index(op.f('ix_data_sources_product_id'), 'data_sources', ['product_id'], unique=False)
            if 'ix_data_sources_workspace_id' not in existing_indices:
                op.create_index(op.f('ix_data_sources_workspace_id'), 'data_sources', ['workspace_id'], unique=False)
        except Exception:
            # If we can't check indices, just skip creating them (they likely already exist)
            pass
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    
    # Drop new data_sources table and recreate old one
    op.drop_table('data_sources')
    op.create_table('data_sources',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('name', sa.VARCHAR(length=255), nullable=False),
    sa.Column('type', sa.VARCHAR(length=100), nullable=False),
    sa.Column('config', sa.TEXT(), nullable=True),
    sa.Column('is_active', sa.BOOLEAN(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.PrimaryKeyConstraint('id')
    )
    op.create_index(op.f('ix_data_sources_id'), 'data_sources', ['id'], unique=False)
    
    # Drop products table
    op.drop_index(op.f('ix_products_workspace_id'), table_name='products')
    op.drop_index(op.f('ix_products_id'), table_name='products')
    op.drop_index('idx_products_workspace_id', table_name='products')
    op.drop_index('idx_products_owner_user_id', table_name='products')
    op.drop_table('products')
    # ### end Alembic commands ###
