"""add_rag_quality_metrics

Revision ID: be303e6b7efc
Revises: 2fb9fd58c3fe
Create Date: 2026-01-16 21:54:29.178948

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql
from sqlalchemy import inspect, text

# revision identifiers, used by Alembic.
revision = 'be303e6b7efc'
down_revision = '2fb9fd58c3fe'
branch_labels = None
depends_on = None


def enum_exists(enum_name):
    """Check if an enum type exists."""
    bind = op.get_bind()
    result = bind.execute(sa.text(
        "SELECT EXISTS (SELECT 1 FROM pg_type WHERE typname = :enum_name)"
    ), {"enum_name": enum_name})
    return result.scalar()


def table_exists(table_name):
    """Check if a table exists."""
    bind = op.get_bind()
    inspector = inspect(bind)
    return table_name in inspector.get_table_names()


def column_exists(table_name, column_name):
    """Check if a column exists in a table."""
    if not table_exists(table_name):
        return False
    bind = op.get_bind()
    inspector = inspect(bind)
    columns = [col['name'] for col in inspector.get_columns(table_name)]
    return column_name in columns


def index_exists(table_name, index_name):
    """Check if an index exists."""
    if not table_exists(table_name):
        return False
    bind = op.get_bind()
    inspector = inspect(bind)
    indexes = [idx['name'] for idx in inspector.get_indexes(table_name)]
    return index_name in indexes


def constraint_exists(table_name, constraint_name):
    """Check if a constraint exists."""
    if not table_exists(table_name):
        return False
    bind = op.get_bind()
    # Query PostgreSQL directly for constraint existence
    result = bind.execute(sa.text(
        "SELECT EXISTS (SELECT 1 FROM pg_constraint WHERE conname = :constraint_name)"
    ), {"constraint_name": constraint_name})
    return result.scalar()


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    # Check if enum exists (it may have been created by a previous migration)
    enum_already_exists = enum_exists('evaldatasetstatus')
    
    # Use create_type=False to prevent SQLAlchemy from trying to create the enum again
    # Note: Using lowercase values to match the existing enum created by previous migration
    status_enum = postgresql.ENUM('draft', 'active', 'archived', name='evaldatasetstatus', create_type=False)
    
    # Only create table if it doesn't exist
    if not table_exists('eval_datasets'):
        op.create_table('eval_datasets',
        sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
        sa.Column('workspace_id', sa.UUID(), nullable=False),
        sa.Column('product_id', sa.UUID(), nullable=False),
        sa.Column('name', sa.String(length=255), nullable=False),
        sa.Column('description', sa.Text(), nullable=True),
        sa.Column('dataset_type', sa.String(length=50), nullable=False),
        sa.Column('version', sa.Integer(), nullable=True),
        sa.Column('status', status_enum, nullable=False),
    sa.Column('extra_metadata', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['product_id'], ['products.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
        op.create_index('idx_eval_datasets_product', 'eval_datasets', ['product_id'], unique=False)
        op.create_index('idx_eval_datasets_status', 'eval_datasets', ['status'], unique=False)
        op.create_index('idx_eval_datasets_type', 'eval_datasets', ['dataset_type'], unique=False)
        op.create_index('idx_eval_datasets_workspace', 'eval_datasets', ['workspace_id'], unique=False)
        op.create_index(op.f('ix_eval_datasets_product_id'), 'eval_datasets', ['product_id'], unique=False)
        op.create_index(op.f('ix_eval_datasets_workspace_id'), 'eval_datasets', ['workspace_id'], unique=False)
    
    # Only create rag_request_logs table if it doesn't exist
    if not table_exists('rag_request_logs'):
        op.create_table('rag_request_logs',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('workspace_id', sa.UUID(), nullable=False),
    sa.Column('product_id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=True),
    sa.Column('version', sa.Integer(), nullable=False),
    sa.Column('query', sa.Text(), nullable=False),
    sa.Column('policy_context', sa.JSON(), nullable=True),
    sa.Column('acl_applied', sa.Boolean(), nullable=False),
    sa.Column('acl_denied', sa.Boolean(), nullable=False),
    sa.Column('retrieved_chunk_ids', sa.JSON(), nullable=True),
    sa.Column('retrieved_doc_ids', sa.JSON(), nullable=True),
    sa.Column('retrieval_scores', sa.JSON(), nullable=True),
    sa.Column('filters_applied', sa.JSON(), nullable=True),
    sa.Column('prompt_hash', sa.String(length=64), nullable=True),
    sa.Column('model', sa.String(length=100), nullable=True),
    sa.Column('temperature', sa.Float(), nullable=True),
    sa.Column('max_tokens', sa.Integer(), nullable=True),
    sa.Column('response', sa.Text(), nullable=True),
    sa.Column('response_tokens', sa.Integer(), nullable=True),
    sa.Column('latency_ms', sa.Float(), nullable=True),
    sa.Column('sampled_for_eval', sa.Boolean(), nullable=False),
    sa.Column('timestamp', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['product_id'], ['products.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='SET NULL'),
    sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
        op.create_index('idx_rag_logs_product_version', 'rag_request_logs', ['product_id', 'version'], unique=False)
        op.create_index('idx_rag_logs_sampled', 'rag_request_logs', ['sampled_for_eval'], unique=False)
        op.create_index('idx_rag_logs_timestamp', 'rag_request_logs', ['timestamp'], unique=False)
        op.create_index('idx_rag_logs_workspace', 'rag_request_logs', ['workspace_id'], unique=False)
        op.create_index(op.f('ix_rag_request_logs_product_id'), 'rag_request_logs', ['product_id'], unique=False)
        op.create_index(op.f('ix_rag_request_logs_timestamp'), 'rag_request_logs', ['timestamp'], unique=False)
        op.create_index(op.f('ix_rag_request_logs_user_id'), 'rag_request_logs', ['user_id'], unique=False)
        op.create_index(op.f('ix_rag_request_logs_workspace_id'), 'rag_request_logs', ['workspace_id'], unique=False)
    
    # Only create eval_dataset_items table if it doesn't exist
    if not table_exists('eval_dataset_items'):
        op.create_table('eval_dataset_items',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('dataset_id', sa.UUID(), nullable=False),
    sa.Column('query', sa.Text(), nullable=False),
    sa.Column('expected_answer', sa.Text(), nullable=True),
    sa.Column('expected_chunks', sa.JSON(), nullable=True),
    sa.Column('expected_docs', sa.JSON(), nullable=True),
    sa.Column('question_type', sa.String(length=50), nullable=True),
    sa.Column('extra_metadata', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.Column('updated_at', sa.DateTime(timezone=True), nullable=True),
    sa.ForeignKeyConstraint(['dataset_id'], ['eval_datasets.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
        op.create_index('idx_eval_dataset_items_dataset', 'eval_dataset_items', ['dataset_id'], unique=False)
        op.create_index(op.f('ix_eval_dataset_items_dataset_id'), 'eval_dataset_items', ['dataset_id'], unique=False)
    
    # Only create rag_quality_metrics table if it doesn't exist
    if not table_exists('rag_quality_metrics'):
        op.create_table('rag_quality_metrics',
    sa.Column('id', sa.UUID(), server_default=sa.text('gen_random_uuid()'), nullable=False),
    sa.Column('workspace_id', sa.UUID(), nullable=False),
    sa.Column('product_id', sa.UUID(), nullable=False),
    sa.Column('eval_run_id', sa.UUID(), nullable=True),
    sa.Column('version', sa.Integer(), nullable=False),
    sa.Column('metric_name', sa.String(length=100), nullable=False),
    sa.Column('value', sa.Float(), nullable=False),
    sa.Column('threshold', sa.Float(), nullable=True),
    sa.Column('passed', sa.Boolean(), nullable=False),
    sa.Column('extra_metadata', sa.JSON(), nullable=True),
    sa.Column('timestamp', sa.DateTime(timezone=True), server_default=sa.text('now()'), nullable=True),
    sa.ForeignKeyConstraint(['eval_run_id'], ['eval_runs.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['product_id'], ['products.id'], ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['workspace_id'], ['workspaces.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
        op.create_index('idx_rag_metrics_eval_run', 'rag_quality_metrics', ['eval_run_id'], unique=False)
        op.create_index('idx_rag_metrics_name_timestamp', 'rag_quality_metrics', ['metric_name', 'timestamp'], unique=False)
        op.create_index('idx_rag_metrics_product_version', 'rag_quality_metrics', ['product_id', 'version'], unique=False)
        op.create_index(op.f('ix_rag_quality_metrics_eval_run_id'), 'rag_quality_metrics', ['eval_run_id'], unique=False)
        op.create_index(op.f('ix_rag_quality_metrics_metric_name'), 'rag_quality_metrics', ['metric_name'], unique=False)
        op.create_index(op.f('ix_rag_quality_metrics_product_id'), 'rag_quality_metrics', ['product_id'], unique=False)
        op.create_index(op.f('ix_rag_quality_metrics_timestamp'), 'rag_quality_metrics', ['timestamp'], unique=False)
        op.create_index(op.f('ix_rag_quality_metrics_workspace_id'), 'rag_quality_metrics', ['workspace_id'], unique=False)
    
    # Other operations that should run regardless (with existence checks)
    if index_exists('eval_queries', 'idx_eval_queries_chunk'):
        op.drop_index('idx_eval_queries_chunk', table_name='eval_queries')
    if not index_exists('eval_queries', 'ix_eval_queries_chunk_id'):
        op.create_index(op.f('ix_eval_queries_chunk_id'), 'eval_queries', ['chunk_id'], unique=False)
    
    # Add columns to eval_runs if they don't exist
    if not column_exists('eval_runs', 'dataset_id'):
        op.add_column('eval_runs', sa.Column('dataset_id', sa.UUID(), nullable=True))
    if not column_exists('eval_runs', 'report_path'):
        op.add_column('eval_runs', sa.Column('report_path', sa.String(length=1000), nullable=True))
    if not column_exists('eval_runs', 'trend_data'):
        op.add_column('eval_runs', sa.Column('trend_data', postgresql.JSONB(astext_type=sa.Text()), nullable=True))
    
    # Create indexes for eval_runs if they don't exist
    if not index_exists('eval_runs', 'idx_eval_runs_dataset'):
        op.create_index('idx_eval_runs_dataset', 'eval_runs', ['dataset_id'], unique=False)
    if not index_exists('eval_runs', 'idx_eval_runs_status'):
        op.create_index('idx_eval_runs_status', 'eval_runs', ['status'], unique=False)
    if not index_exists('eval_runs', 'ix_eval_runs_dataset_id'):
        op.create_index(op.f('ix_eval_runs_dataset_id'), 'eval_runs', ['dataset_id'], unique=False)
    
    # Create foreign key if it doesn't exist
    if table_exists('eval_runs') and column_exists('eval_runs', 'dataset_id'):
        bind = op.get_bind()
        inspector = inspect(bind)
        fk_exists = False
        for fk in inspector.get_foreign_keys('eval_runs'):
            if fk['referred_table'] == 'eval_datasets' and 'dataset_id' in fk['constrained_columns']:
                fk_exists = True
                break
        if not fk_exists:
            op.create_foreign_key(None, 'eval_runs', 'eval_datasets', ['dataset_id'], ['id'], ondelete='SET NULL')
    
    # Add column to products if it doesn't exist
    if not column_exists('products', 'rag_quality_thresholds'):
        op.add_column('products', sa.Column('rag_quality_thresholds', sa.JSON(), nullable=True))
    
    # Drop indexes only if they exist
    if index_exists('products', 'idx_products_workspace_active'):
        op.drop_index('idx_products_workspace_active', table_name='products', postgresql_where='(deleted_at IS NULL)')
    if index_exists('products', 'idx_products_workspace_created_at'):
        op.drop_index('idx_products_workspace_created_at', table_name='products')
    if index_exists('products', 'idx_products_workspace_status'):
        op.drop_index('idx_products_workspace_status', table_name='products')
    if index_exists('products', 'idx_products_workspace_version'):
        op.drop_index('idx_products_workspace_version', table_name='products')
    
    # Create indexes only if they don't exist
    if not index_exists('products', 'ix_products_id'):
        op.create_index(op.f('ix_products_id'), 'products', ['id'], unique=False)
    if not index_exists('products', 'ix_products_workspace_id'):
        op.create_index(op.f('ix_products_workspace_id'), 'products', ['workspace_id'], unique=False)
    
    # Drop columns only if they exist
    if column_exists('products', 'deleted_at'):
        op.drop_column('products', 'deleted_at')
    if column_exists('users', 'deleted_at'):
        op.drop_column('users', 'deleted_at')
    
    # Drop index only if it exists
    if index_exists('workspace_members', 'ux_workspace_members_workspace_user'):
        op.drop_index('ux_workspace_members_workspace_user', table_name='workspace_members')
    
    # Create index only if it doesn't exist
    if not index_exists('workspace_members', 'ix_workspace_members_id'):
        op.create_index(op.f('ix_workspace_members_id'), 'workspace_members', ['id'], unique=False)
    
    # Drop index only if it exists
    if index_exists('workspaces', 'idx_workspaces_owner_id'):
        op.drop_index('idx_workspaces_owner_id', table_name='workspaces')
    
    # Create index only if it doesn't exist
    if not index_exists('workspaces', 'ix_workspaces_id'):
        op.create_index(op.f('ix_workspaces_id'), 'workspaces', ['id'], unique=False)
    
    # Drop constraint only if it exists
    if constraint_exists('workspaces', 'workspaces_owner_id_fkey'):
        op.drop_constraint('workspaces_owner_id_fkey', 'workspaces', type_='foreignkey')
    
    # Drop columns only if they exist
    if column_exists('workspaces', 'owner_id'):
        op.drop_column('workspaces', 'owner_id')
    if column_exists('workspaces', 'deleted_at'):
        op.drop_column('workspaces', 'deleted_at')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.add_column('workspaces', sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('workspaces', sa.Column('owner_id', sa.UUID(), autoincrement=False, nullable=True))
    op.create_foreign_key('workspaces_owner_id_fkey', 'workspaces', 'users', ['owner_id'], ['id'])
    op.drop_index(op.f('ix_workspaces_id'), table_name='workspaces')
    op.create_index('idx_workspaces_owner_id', 'workspaces', ['owner_id'], unique=False)
    op.drop_index(op.f('ix_workspace_members_id'), table_name='workspace_members')
    op.create_index('ux_workspace_members_workspace_user', 'workspace_members', ['workspace_id', 'user_id'], unique=False)
    op.add_column('users', sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.add_column('products', sa.Column('deleted_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True))
    op.drop_index(op.f('ix_products_workspace_id'), table_name='products')
    op.drop_index(op.f('ix_products_id'), table_name='products')
    op.create_index('idx_products_workspace_version', 'products', ['workspace_id', 'current_version'], unique=False)
    op.create_index('idx_products_workspace_status', 'products', ['workspace_id', 'status'], unique=False)
    op.create_index('idx_products_workspace_created_at', 'products', ['workspace_id', sa.text('created_at DESC')], unique=False)
    op.create_index('idx_products_workspace_active', 'products', ['workspace_id', sa.text('created_at DESC')], unique=False, postgresql_where='(deleted_at IS NULL)')
    op.drop_column('products', 'rag_quality_thresholds')
    op.drop_constraint(None, 'eval_runs', type_='foreignkey')
    op.drop_index(op.f('ix_eval_runs_dataset_id'), table_name='eval_runs')
    op.drop_index('idx_eval_runs_status', table_name='eval_runs')
    op.drop_index('idx_eval_runs_dataset', table_name='eval_runs')
    op.drop_column('eval_runs', 'trend_data')
    op.drop_column('eval_runs', 'report_path')
    op.drop_column('eval_runs', 'dataset_id')
    op.drop_index(op.f('ix_eval_queries_chunk_id'), table_name='eval_queries')
    op.create_index('idx_eval_queries_chunk', 'eval_queries', ['chunk_id'], unique=False)
    op.drop_index(op.f('ix_rag_quality_metrics_workspace_id'), table_name='rag_quality_metrics')
    op.drop_index(op.f('ix_rag_quality_metrics_timestamp'), table_name='rag_quality_metrics')
    op.drop_index(op.f('ix_rag_quality_metrics_product_id'), table_name='rag_quality_metrics')
    op.drop_index(op.f('ix_rag_quality_metrics_metric_name'), table_name='rag_quality_metrics')
    op.drop_index(op.f('ix_rag_quality_metrics_eval_run_id'), table_name='rag_quality_metrics')
    op.drop_index('idx_rag_metrics_product_version', table_name='rag_quality_metrics')
    op.drop_index('idx_rag_metrics_name_timestamp', table_name='rag_quality_metrics')
    op.drop_index('idx_rag_metrics_eval_run', table_name='rag_quality_metrics')
    op.drop_table('rag_quality_metrics')
    op.drop_index(op.f('ix_eval_dataset_items_dataset_id'), table_name='eval_dataset_items')
    op.drop_index('idx_eval_dataset_items_dataset', table_name='eval_dataset_items')
    op.drop_table('eval_dataset_items')
    op.drop_index(op.f('ix_rag_request_logs_workspace_id'), table_name='rag_request_logs')
    op.drop_index(op.f('ix_rag_request_logs_user_id'), table_name='rag_request_logs')
    op.drop_index(op.f('ix_rag_request_logs_timestamp'), table_name='rag_request_logs')
    op.drop_index(op.f('ix_rag_request_logs_product_id'), table_name='rag_request_logs')
    op.drop_index('idx_rag_logs_workspace', table_name='rag_request_logs')
    op.drop_index('idx_rag_logs_timestamp', table_name='rag_request_logs')
    op.drop_index('idx_rag_logs_sampled', table_name='rag_request_logs')
    op.drop_index('idx_rag_logs_product_version', table_name='rag_request_logs')
    op.drop_table('rag_request_logs')
    op.drop_index(op.f('ix_eval_datasets_workspace_id'), table_name='eval_datasets')
    op.drop_index(op.f('ix_eval_datasets_product_id'), table_name='eval_datasets')
    op.drop_index('idx_eval_datasets_workspace', table_name='eval_datasets')
    op.drop_index('idx_eval_datasets_type', table_name='eval_datasets')
    op.drop_index('idx_eval_datasets_status', table_name='eval_datasets')
    op.drop_index('idx_eval_datasets_product', table_name='eval_datasets')
    op.drop_table('eval_datasets')
    # ### end Alembic commands ###
